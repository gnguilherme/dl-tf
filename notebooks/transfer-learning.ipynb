{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mnet = MobileNetV2(input_shape=(224, 224, 3), include_top=False)\r\n",
    "mnet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow_datasets as tfds\r\n",
    "tfds.disable_progress_bar()\r\n",
    "\r\n",
    "dataset, metadata = tfds.load('deep_weeds', as_supervised=True, with_info=True)\r\n",
    "train_dataset = dataset['train']\r\n",
    "\r\n",
    "class_names = metadata.features['label'].names\r\n",
    "print(\"Class names: {}\".format(class_names))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def normalize(images, labels):\r\n",
    "    images = tf.cast(images, tf.float32)\r\n",
    "    images /= 255\r\n",
    "    return images, labels\r\n",
    "\r\n",
    "def resize(images, labels):\r\n",
    "    images = tf.image.resize(images, size=(224, 224))\r\n",
    "\r\n",
    "    return images, labels\r\n",
    "\r\n",
    "def transform_images(images, labels):\r\n",
    "    images, labels = resize(images, labels)\r\n",
    "    images, labels = normalize(images, labels)\r\n",
    "\r\n",
    "    return images, labels\r\n",
    "\r\n",
    "train_dataset =  train_dataset.map(transform_images)\r\n",
    "train_dataset =  train_dataset.cache()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for image, labels in train_dataset.take(1):\r\n",
    "    break\r\n",
    "pred = mnet(tf.expand_dims(image, 0))\r\n",
    "pred.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\r\n",
    "mnet.trainable = False\r\n",
    "gap = GlobalAveragePooling2D()\r\n",
    "dropout = Dropout(rate=0.25)\r\n",
    "fc1 = Dense(units=len(class_names), activation=tf.nn.softmax)\r\n",
    "layers =[\r\n",
    "    mnet,\r\n",
    "    gap,\r\n",
    "    dropout,\r\n",
    "    fc1,\r\n",
    "]\r\n",
    "model = tf.keras.models.Sequential(layers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(\r\n",
    "    optimizer='adam',\r\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\r\n",
    "    metrics=['accuracy']\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "BATCH_SIZE = 32\r\n",
    "num_train_examples = metadata.splits['train'].num_examples\r\n",
    "train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\r\n",
    "\r\n",
    "model.fit(train_dataset, epochs=10, steps_per_epoch=np.ceil(num_train_examples/BATCH_SIZE))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tf': venv)"
  },
  "interpreter": {
   "hash": "a8da867777bda7a36ba79ef652ca0450f4f134accc992c4581dd001533c4e60a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}